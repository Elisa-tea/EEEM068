{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FUrn8O3DACP4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a652d012-0507-4bf1-fbae-795b9beea25c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "ezWcNB66APln",
        "jupyter": {
          "outputs_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "542a2c44-dfe8-4f29-a18d-35021820a6c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1RhMfnXLlQVPT4O9cyTDKsbWy2LL-hbbY\n",
            "From (redirected): https://drive.google.com/uc?id=1RhMfnXLlQVPT4O9cyTDKsbWy2LL-hbbY&confirm=t&uuid=37d0f79f-af75-4b87-ab0f-5268edfe49c2\n",
            "To: /content/HMDB_simp_clean.zip\n",
            "100%|██████████| 2.03G/2.03G [00:20<00:00, 101MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download and extraction complete!\n"
          ]
        }
      ],
      "source": [
        "import gdown\n",
        "import zipfile\n",
        "#!pip install transformers torch torchvision datasets evaluate torchmetrics\n",
        "\n",
        "# Google Drive file ID\n",
        "file_id = \"1RhMfnXLlQVPT4O9cyTDKsbWy2LL-hbbY\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "# Download file\n",
        "output = \"HMDB_simp_clean.zip\"\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(output, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\".\")\n",
        "\n",
        "print(\"Download and extraction complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YBWzeuZZOz6R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "907a976b-5687-4a5a-e80d-ad1ebdfcb5cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.11/dist-packages (1.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (0.14.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch torchvision datasets evaluate torchmetrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NjqkzwpFZ2t"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okOhTovRFbzP"
      },
      "source": [
        "## Create dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "i2jJmcaGAuv1"
      },
      "outputs": [],
      "source": [
        "CATEGORY_INDEX = {\n",
        "    \"brush_hair\": 0,\n",
        "    \"cartwheel\": 1,\n",
        "    \"catch\": 2,\n",
        "    \"chew\": 3,\n",
        "    \"climb\": 4,\n",
        "    \"climb_stairs\": 5,\n",
        "    \"draw_sword\": 6,\n",
        "    \"eat\": 7,\n",
        "    \"fencing\": 8,\n",
        "    \"flic_flac\": 9,\n",
        "    \"golf\": 10,\n",
        "    \"handstand\": 11,\n",
        "    \"kiss\": 12,\n",
        "    \"pick\": 13,\n",
        "    \"pour\": 14,\n",
        "    \"pullup\": 15,\n",
        "    \"pushup\": 16,\n",
        "    \"ride_bike\": 17,\n",
        "    \"shoot_bow\": 18,\n",
        "    \"shoot_gun\": 19,\n",
        "    \"situp\": 20,\n",
        "    \"smile\": 21,\n",
        "    \"smoke\": 22,\n",
        "    \"throw\": 23,\n",
        "    \"wave\": 24\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "P--_dzefBom3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from tqdm.notebook import trange, tqdm\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "# Transformation: Resize to 224x224 and Convert to Tensor\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "def load_sampled_frames(frame_dir, frame_rate=8):\n",
        "    \"\"\"\n",
        "    Load every [frame_rate]-th frame from a directory and apply transformations.\n",
        "    \"\"\"\n",
        "    frame_files = sorted(os.listdir(frame_dir))  # Ensure frames are in order\n",
        "    sampled_frames = []\n",
        "    frame_metadata = []\n",
        "\n",
        "    for i in range(0, len(frame_files), frame_rate):\n",
        "        frame_path = os.path.join(frame_dir, frame_files[i])\n",
        "        if os.path.isfile(frame_path):\n",
        "          frame = Image.open(frame_path).convert(\"RGB\")  # Convert to RGB\n",
        "          frame = transform(frame)  # Apply transformations\n",
        "          sampled_frames.append(frame)\n",
        "          frame_metadata.append({'index': i, 'used_in_clip': False, 'file_path': frame_path}) #set up\n",
        "        else:\n",
        "          print(f\"skiping {frame_path}\")\n",
        "\n",
        "    return sampled_frames, frame_metadata  # List of torch tensors\n",
        "\n",
        "def create_clips(frames, frame_metadata, clip_size=8):\n",
        "    \"\"\"\n",
        "    Given a list of sampled frames, create multiple [clip_size]-frame clips.\n",
        "    \"\"\"\n",
        "    clips = []\n",
        "    #clip_indices = []\n",
        "    #updated_metadata = []\n",
        "\n",
        "    clips = make_clip(frames, random_horizontal_flip, 8, 32)\n",
        "    return clips\n",
        "\n",
        "\n",
        "def make_clip(video, augmentation_type, clip_len=8, sample_rate=32):\n",
        "    \"\"\"\n",
        "    Creates a clip from a video list of tensors based on the length conditions.\n",
        "\n",
        "    Args:\n",
        "        video (List[Tensor]): List of frame tensors, each of shape (C, H, W).\n",
        "        augmentation_type (callable): Augmentation function applied to each frame.\n",
        "        clip_len (int): Number of frames in the final clip.\n",
        "        sample_rate (int): Interval between sampled frames.\n",
        "\n",
        "    Returns:\n",
        "        Tensor: A single clip tensor of shape (clip_len, C, H, W).\n",
        "    \"\"\"\n",
        "\n",
        "    num_frames = len(video)\n",
        "\n",
        "    if num_frames >= clip_len * sample_rate:\n",
        "        # Sample every `sample_rate` frames to create an `clip_len`-frame clip\n",
        "        clip = [video[i] for i in range(0, clip_len * sample_rate, sample_rate)]\n",
        "\n",
        "    else:\n",
        "        # Not enough frames → get what you can + repeat with circular sampling\n",
        "        n = num_frames // sample_rate\n",
        "        n_clip = [video[i] for i in range(0, n * sample_rate, sample_rate)]\n",
        "        remaining_frames_needed = clip_len - len(n_clip)\n",
        "\n",
        "        additional_frames = []\n",
        "        start_idx = 0\n",
        "        while len(additional_frames) < remaining_frames_needed:\n",
        "            idx = (start_idx + sample_rate) % num_frames  # circular index\n",
        "            additional_frames.append(video[idx])\n",
        "            start_idx += sample_rate\n",
        "\n",
        "        clip = n_clip + additional_frames\n",
        "\n",
        "    # Apply augmentation and stack into a (clip_len, C, H, W) tensor\n",
        "    clip = [augmentation_type(f) for f in clip]\n",
        "    clip = torch.stack(clip)\n",
        "\n",
        "\n",
        "    return clip\n",
        "\n",
        "\n",
        "def vertical_down_translation(frame, shift=20):\n",
        "    \"\"\"\n",
        "    Apply vertical down translation to an image frame.\n",
        "\n",
        "    Args:\n",
        "        frame (Tensor): Image tensor of shape (C, H, W).\n",
        "        shift (int): Number of pixels to shift the image downward.\n",
        "\n",
        "    Returns:\n",
        "        Tensor: Translated image tensor of shape (C, H, W).\n",
        "    \"\"\"\n",
        "    C, H, W = frame.shape  # Get channel, height, width\n",
        "\n",
        "    # Create a black canvas (zero tensor)\n",
        "    translated_frame = torch.zeros_like(frame)\n",
        "\n",
        "    # Shift the original image down, filling the top with black pixels\n",
        "    if shift < H:  # Ensure shift is within bounds\n",
        "        translated_frame[:, shift:, :] = frame[:, :-shift, :]\n",
        "\n",
        "    return translated_frame\n",
        "\n",
        "\n",
        "def random_horizontal_flip(frame, p=0.8):\n",
        "    \"\"\"\n",
        "    #this highly preserve the content of the image#\n",
        "    Apply random horizontal flip to an image frame.\n",
        "\n",
        "    Args:\n",
        "        frame (Tensor): Image tensor of shape (C, H, W).\n",
        "        p (float): Probability of applying the flip.\n",
        "\n",
        "    Returns:\n",
        "        Tensor: Horizontally flipped image tensor of shape (C, H, W) if flipped, else the original.\n",
        "    \"\"\"\n",
        "    if random.random() < p:  # Flip with probability p\n",
        "        return F.hflip(frame)\n",
        "    return frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EZ5uc9RyCaP8"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = \"/content/HMDB_simp_clean\"\n",
        "\n",
        "import random\n",
        "\n",
        "def split_sources(dataset_path, train_ratio=0.8):\n",
        "    \"\"\"\n",
        "    Splits source folders into train and val sets before processing clips.\n",
        "    Ensures that all clips from a source video stay in the same set.\n",
        "    \"\"\"\n",
        "    train_sources = {}\n",
        "    val_sources = {}\n",
        "\n",
        "    for category in os.listdir(dataset_path):  # Iterate over action categories\n",
        "        category_path = os.path.join(dataset_path, category)\n",
        "        if not os.path.isdir(category_path):\n",
        "            continue\n",
        "\n",
        "        instances = os.listdir(category_path)  # List all source folders (video IDs)\n",
        "        random.shuffle(instances)  # Shuffle instances before splitting\n",
        "\n",
        "        split_idx = int(len(instances) * train_ratio)\n",
        "        train_sources[category] = instances[:split_idx]  # First 80% for training\n",
        "        val_sources[category] = instances[split_idx:]  # Last 20% for validation\n",
        "\n",
        "    return train_sources, val_sources\n",
        "\n",
        "\n",
        "def process_dataset(dataset_path, sources_dict):\n",
        "    \"\"\"\n",
        "    Processes dataset based on a predefined list of sources.\n",
        "    \"\"\"\n",
        "    dataset = []\n",
        "    all_updated_metadata = []\n",
        "\n",
        "    for category, instances in tqdm(sources_dict.items()):\n",
        "        category_path = os.path.join(dataset_path, category)\n",
        "\n",
        "        for instance in instances:\n",
        "            instance_path = os.path.join(category_path, instance)\n",
        "            if not os.path.isdir(instance_path):\n",
        "                print(f\"Skipping non-directory file: {instance_path}\")\n",
        "                continue  # Skip non-directory files\n",
        "\n",
        "            # Load sampled frames\n",
        "            frames, frame_metadata = load_sampled_frames(instance_path)\n",
        "\n",
        "            # Create 8-frame clips\n",
        "            clips  =  create_clips(frames, frame_metadata, 8)\n",
        "            dataset.append((clips, CATEGORY_INDEX[category]))\n",
        "\n",
        "            \"\"\"for i, clip in enumerate(clips):\n",
        "                dataset.append((clip, CATEGORY_INDEX[category]))  # Store (clip, label)\"\"\"\n",
        "                #all_updated_metadata.append(updated_metadata[i])\n",
        "            #print(f\"len(dataset) = {len(dataset)}\")\n",
        "\n",
        "    return dataset  # List of (clip, label)\n",
        "\n",
        "class VideoDataset(Dataset):\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        clip, label = self.dataset[idx]\n",
        "        return clip, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "from torch.utils.data import default_collate\n",
        "\n",
        "class VideoDataCollator:\n",
        "    \"\"\"\n",
        "    Custom data collator for TimeSFormer.\n",
        "    Converts (clip, label) tuples into a dictionary format.\n",
        "    \"\"\"\n",
        "    def __call__(self, features):\n",
        "        clips, labels = zip(*features)  # Unpack (clip, label)\n",
        "        batch = {\n",
        "            \"pixel_values\": torch.stack(clips),  # Stack clips into batch\n",
        "            \"labels\": torch.tensor(labels, dtype=torch.long)  # Convert labels to tensor\n",
        "        }\n",
        "        return batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XJVUutawfSt4"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def count_classes(dataset):\n",
        "    \"\"\"\n",
        "    Function to print the number of clips of 8 created per class\n",
        "    \"\"\"\n",
        "    class_counts = Counter(label for _, label in dataset)\n",
        "    sorted_class_counts = dict(sorted(class_counts.items()))\n",
        "\n",
        "    for class_label, count in sorted_class_counts.items():\n",
        "        print(f\"Class {class_label}: {count} clips of 8\")\n",
        "\n",
        "    return sorted_class_counts\n",
        "\n",
        "#count_classes(train_dataset);\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "1f76564a13834e74a0230effda9d9b0b",
            "6fe08a00d6aa462f97aaf477d1311892",
            "7c24487144f64baa8200b3b28e4e7093",
            "a879b2600a0043dcbaf9993fdf1816ee",
            "99ea3fedf62c446e8c101a8274ecd8dd",
            "d699a544d0bc4494b0e71636b3175df7",
            "6a018a56bff94a5892ba6db1bdc8e0b0",
            "80da5cceb457428ea6981cdb2a1eb41c",
            "d99ef52f70f84058b946e2af45f521e3",
            "8b27b8e241bd41dcafbdc5e4ad3901f8",
            "373fc8ecc00848499ceed775df040d9d",
            "f5c07c1353bb4e038c6664e725083871",
            "3380d9b2f37a4331892f9ec9ddf614bb",
            "811b2a905ab540068cc88c2b81d604a4",
            "41f82760ee184b7f998d97e494050958",
            "62c7bff490f84c2fa5b3f1e5454a11e1",
            "a5138b8ac5274f63bee2aa1d651bb89a",
            "cf90a69701b141b59b7ff8076bddb8ed",
            "ee25bbc44126423fa43c6581ddc1b332",
            "2972a857847843f0892895e7d3939263",
            "7b97df37e44542799f7f88f8e90c66e7",
            "571fd7ce532e4cf481aff3fbc19ba24d"
          ]
        },
        "collapsed": true,
        "id": "dWD2A1WTCTO7",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "d15f8e4a-af82-49dd-98ef-352e6a4af7d0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f76564a13834e74a0230effda9d9b0b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "skiping /content/HMDB_simp_clean/wave/C6E07F42/.ipynb_checkpoints\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5c07c1353bb4e038c6664e725083871"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total clips: 1250, Train: 1000, Val: 250\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Split source folders into train & val\n",
        "train_sources, val_sources = split_sources(DATASET_PATH)\n",
        "\n",
        "# Process train and val sets separately\n",
        "train_dataset  = process_dataset(DATASET_PATH, train_sources)\n",
        "val_dataset = process_dataset(DATASET_PATH, val_sources)\n",
        "\n",
        "dataset_size = len(train_dataset) + len(val_dataset)\n",
        "\n",
        "print(f\"Total clips: {dataset_size}, Train: {len(train_dataset)}, Val: {len(val_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr = [0]*25\n",
        "\n",
        "for i in range(len(train_dataset)):\n",
        "  arr[train_dataset[i][1]] += 1\n",
        "\n",
        "print(arr)\n",
        "\n",
        "arr2 = [0]*25\n",
        "for i in range(len(val_dataset)):\n",
        "  arr2[val_dataset[i][1]] += 1\n",
        "print(arr2)\n",
        "print(len(train_sources))\n",
        "print(f\"Total clips: {dataset_size}, Train: {len(train_dataset)}, Val: {len(val_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yx4qeBwHQGI_",
        "outputId": "9d7650b7-c118-4fe4-a8cd-5d9b9bd1a2fc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40]\n",
            "[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
            "25\n",
            "Total clips: 1250, Train: 1000, Val: 250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E38OobPnIIb6"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2Jrj0STIKLa"
      },
      "source": [
        "## TimeSFormer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FSbE-vwYICqB",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "4aa8d11a-526a-47ec-cb3e-0263b51609c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/videomae/feature_extraction_videomae.py:28: FutureWarning: The class VideoMAEFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use VideoMAEImageProcessor instead.\n",
            "  warnings.warn(\n",
            "Some weights of TimesformerForVideoClassification were not initialized from the model checkpoint at facebook/timesformer-base-finetuned-k400 and are newly initialized because the shapes did not match:\n",
            "- classifier.weight: found shape torch.Size([400, 768]) in the checkpoint and torch.Size([25, 768]) in the model instantiated\n",
            "- classifier.bias: found shape torch.Size([400]) in the checkpoint and torch.Size([25]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model on: cuda\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoFeatureExtractor, AutoModelForVideoClassification\n",
        "\n",
        "\n",
        "extractor = AutoFeatureExtractor.from_pretrained(\"facebook/timesformer-base-finetuned-k400\")\n",
        "model = AutoModelForVideoClassification.from_pretrained(\n",
        "    \"facebook/timesformer-base-finetuned-k400\",\n",
        "    num_labels=len(CATEGORY_INDEX),  # Adjust for our dataset\n",
        "    ignore_mismatched_sizes=True,\n",
        ")\n",
        "\n",
        "# Send model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print(f\"Model on: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FZCcJnr2JL5X"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchmetrics\n",
        "import evaluate\n",
        "import numpy as np\n",
        "from transformers import AutoFeatureExtractor, AutoModelForVideoClassification, TrainingArguments, Trainer\n",
        "\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "top5_metric = torchmetrics.classification.Accuracy(top_k=5, task=\"multiclass\", num_classes=len(CATEGORY_INDEX)).to(device)\n",
        "\n",
        "# Compute Metrics Function\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = torch.tensor(logits).argmax(dim=1)\n",
        "\n",
        "    # Compute Accuracy\n",
        "    top1_acc = accuracy_metric.compute(predictions=predictions.numpy(), references=labels)[\"accuracy\"]\n",
        "\n",
        "    # Compute Top-5 Accuracy\n",
        "    top5_acc = top5_metric(torch.tensor(logits).to(device), torch.tensor(labels).to(device)).item()\n",
        "\n",
        "    # Compute F1-score (macro)\n",
        "    f1 = f1_metric.compute(predictions=predictions.numpy(), references=labels, average=\"macro\")[\"f1\"]\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": top1_acc,\n",
        "        \"top-5 accuracy\": top5_acc,\n",
        "        \"f1-score\": f1\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "id": "ARn0w9fRK1q3",
        "outputId": "3a666967-8fe2-41ee-969c-f5be6c087978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-00dbc74460ea>:22: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlisik-tea\u001b[0m (\u001b[33mlisik-tea-university-of-surrey\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250419_054822-71ytwsgf</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/lisik-tea-university-of-surrey/huggingface/runs/71ytwsgf' target=\"_blank\">./timesformer_output</a></strong> to <a href='https://wandb.ai/lisik-tea-university-of-surrey/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/lisik-tea-university-of-surrey/huggingface' target=\"_blank\">https://wandb.ai/lisik-tea-university-of-surrey/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/lisik-tea-university-of-surrey/huggingface/runs/71ytwsgf' target=\"_blank\">https://wandb.ai/lisik-tea-university-of-surrey/huggingface/runs/71ytwsgf</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1250/1250 45:19, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Top-5 accuracy</th>\n",
              "      <th>F1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.871100</td>\n",
              "      <td>0.755521</td>\n",
              "      <td>0.756000</td>\n",
              "      <td>0.964000</td>\n",
              "      <td>0.734011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.167000</td>\n",
              "      <td>0.564329</td>\n",
              "      <td>0.820000</td>\n",
              "      <td>0.984000</td>\n",
              "      <td>0.819608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.006300</td>\n",
              "      <td>0.538788</td>\n",
              "      <td>0.844000</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>0.844732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.003200</td>\n",
              "      <td>0.557536</td>\n",
              "      <td>0.832000</td>\n",
              "      <td>0.976000</td>\n",
              "      <td>0.830470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.001400</td>\n",
              "      <td>0.570068</td>\n",
              "      <td>0.832000</td>\n",
              "      <td>0.976000</td>\n",
              "      <td>0.830649</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1250, training_loss=0.3466434930428863, metrics={'train_runtime': 2775.5022, 'train_samples_per_second': 1.801, 'train_steps_per_second': 0.45, 'total_flos': 4.38137551724544e+18, 'train_loss': 0.3466434930428863, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./timesformer_output\",  # Save checkpoints\n",
        "    eval_strategy=\"epoch\",  # Evaluate after every epoch\n",
        "    save_strategy=\"epoch\",  # Save model after each epoch\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=5,\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",  # TensorBoard logs\n",
        "    logging_steps=10,\n",
        "    save_total_limit=2,  # Keep only last 2 checkpoints\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    push_to_hub=False\n",
        ")\n",
        "\n",
        "data_collator = VideoDataCollator()\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=extractor,  # Feature extractor\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "# Train Model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8ifQW4IDlTiU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1f76564a13834e74a0230effda9d9b0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6fe08a00d6aa462f97aaf477d1311892",
              "IPY_MODEL_7c24487144f64baa8200b3b28e4e7093",
              "IPY_MODEL_a879b2600a0043dcbaf9993fdf1816ee"
            ],
            "layout": "IPY_MODEL_99ea3fedf62c446e8c101a8274ecd8dd"
          }
        },
        "6fe08a00d6aa462f97aaf477d1311892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d699a544d0bc4494b0e71636b3175df7",
            "placeholder": "​",
            "style": "IPY_MODEL_6a018a56bff94a5892ba6db1bdc8e0b0",
            "value": "100%"
          }
        },
        "7c24487144f64baa8200b3b28e4e7093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80da5cceb457428ea6981cdb2a1eb41c",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d99ef52f70f84058b946e2af45f521e3",
            "value": 25
          }
        },
        "a879b2600a0043dcbaf9993fdf1816ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b27b8e241bd41dcafbdc5e4ad3901f8",
            "placeholder": "​",
            "style": "IPY_MODEL_373fc8ecc00848499ceed775df040d9d",
            "value": " 25/25 [00:52&lt;00:00,  1.73s/it]"
          }
        },
        "99ea3fedf62c446e8c101a8274ecd8dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d699a544d0bc4494b0e71636b3175df7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a018a56bff94a5892ba6db1bdc8e0b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80da5cceb457428ea6981cdb2a1eb41c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d99ef52f70f84058b946e2af45f521e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b27b8e241bd41dcafbdc5e4ad3901f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "373fc8ecc00848499ceed775df040d9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5c07c1353bb4e038c6664e725083871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3380d9b2f37a4331892f9ec9ddf614bb",
              "IPY_MODEL_811b2a905ab540068cc88c2b81d604a4",
              "IPY_MODEL_41f82760ee184b7f998d97e494050958"
            ],
            "layout": "IPY_MODEL_62c7bff490f84c2fa5b3f1e5454a11e1"
          }
        },
        "3380d9b2f37a4331892f9ec9ddf614bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5138b8ac5274f63bee2aa1d651bb89a",
            "placeholder": "​",
            "style": "IPY_MODEL_cf90a69701b141b59b7ff8076bddb8ed",
            "value": "100%"
          }
        },
        "811b2a905ab540068cc88c2b81d604a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee25bbc44126423fa43c6581ddc1b332",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2972a857847843f0892895e7d3939263",
            "value": 25
          }
        },
        "41f82760ee184b7f998d97e494050958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b97df37e44542799f7f88f8e90c66e7",
            "placeholder": "​",
            "style": "IPY_MODEL_571fd7ce532e4cf481aff3fbc19ba24d",
            "value": " 25/25 [00:11&lt;00:00,  1.81it/s]"
          }
        },
        "62c7bff490f84c2fa5b3f1e5454a11e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5138b8ac5274f63bee2aa1d651bb89a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf90a69701b141b59b7ff8076bddb8ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee25bbc44126423fa43c6581ddc1b332": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2972a857847843f0892895e7d3939263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b97df37e44542799f7f88f8e90c66e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "571fd7ce532e4cf481aff3fbc19ba24d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}