{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnjanDutta/EEEM068/blob/main/Notebooks/Human_Action_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets download the pickled dataset from the above link."
      ],
      "metadata": {
        "id": "sVrBKULQUi5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown torch torchvision datasets evaluate torchmetrics transformers random"
      ],
      "metadata": {
        "id": "0G0OntOa3vgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from tqdm.notebook import trange, tqdm\n",
        "import gdown\n",
        "import zipfile\n",
        "import random"
      ],
      "metadata": {
        "id": "MEenE3X_4FU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset\n",
        "\n",
        "\n",
        "# Google Drive file ID\n",
        "file_id = \"1BqMBtsuvb6mTpiZUZ9WKcJA8f1hkI2yX\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "# Download file\n",
        "output = \"HMDB_simp.zip\"\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(output, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\".\")\n",
        "\n",
        "print(\"Download and extraction complete!\")"
      ],
      "metadata": {
        "id": "JC1zNcUjwDmQ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CATEGORY_INDEX = {\n",
        "    \"brush_hair\": 0,\n",
        "    \"cartwheel\": 1,\n",
        "    \"catch\": 2,\n",
        "    \"chew\": 3,\n",
        "    \"climb\": 4,\n",
        "    \"climb_stairs\": 5,\n",
        "    \"draw_sword\": 6,\n",
        "    \"eat\": 7,\n",
        "    \"fencing\": 8,\n",
        "    \"flic_flac\": 9,\n",
        "    \"golf\": 10,\n",
        "    \"handstand\": 11,\n",
        "    \"kiss\": 12,\n",
        "    \"pick\": 13,\n",
        "    \"pour\": 14,\n",
        "    \"pullup\": 15,\n",
        "    \"pushup\": 16,\n",
        "    \"ride_bike\": 17,\n",
        "    \"shoot_bow\": 18,\n",
        "    \"shoot_gun\": 19,\n",
        "    \"situp\": 20,\n",
        "    \"smile\": 21,\n",
        "    \"smoke\": 22,\n",
        "    \"throw\": 23,\n",
        "    \"wave\": 24\n",
        "}"
      ],
      "metadata": {
        "id": "O8ZxrC1tigVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "def load_sampled_frames(frame_dir, frame_rate=8):\n",
        "    \"\"\"\n",
        "    Load every [frame_rate]-th frame from a directory and apply transformations.\n",
        "    \"\"\"\n",
        "    frame_files = sorted(os.listdir(frame_dir))  # Ensure frames are in order\n",
        "    sampled_frames = []\n",
        "    frame_metadata = []\n",
        "\n",
        "    for i in range(0, len(frame_files), frame_rate):\n",
        "        frame_path = os.path.join(frame_dir, frame_files[i])\n",
        "        frame = Image.open(frame_path).convert(\"RGB\")  # Convert to RGB\n",
        "        frame = transform(frame)  # Apply transformations\n",
        "        sampled_frames.append(frame)\n",
        "        frame_metadata.append({'index': i, 'used_in_clip': False, 'file_path': frame_path}) #set up\n",
        "\n",
        "    return sampled_frames, frame_metadata  # List of torch tensors\n",
        "\n",
        "def create_clips(frames, frame_metadata, clip_size=8):\n",
        "    \"\"\"\n",
        "    Given a list of sampled frames, create multiple [clip_size]-frame clips.\n",
        "    \"\"\"\n",
        "    clips = []\n",
        "    clip_indices = []\n",
        "    updated_metadata = []\n",
        "    if len(frames) < clip_size:\n",
        "        return clips, updated_metadata, clip_indices  # Not enough frames to create a clip\n",
        "    for i in range(0, len(frames) - clip_size + 1, clip_size):  # Sliding window\n",
        "        clip = torch.stack(frames[i:i + clip_size])  # Stack into (clip_size, 3, 224, 224)\n",
        "        clips.append(clip)\n",
        "        clip_indices.append([frame_metadata[j]['index'] for j in range(i, i + clip_size)])\n",
        "        clip_metadata = [frame_metadata[j]['file_path'] for j in range(i, i + clip_size)]\n",
        "        updated_metadata.append(clip_metadata)\n",
        "\n",
        "    return clips, updated_metadata, clip_indices\n",
        "\n",
        "\n",
        "DATASET_PATH = \"/content/HMDB_simp\" # specified path\n",
        "\n",
        "def split_sources(dataset_path, train_ratio=0.8):\n",
        "    \"\"\"\n",
        "    Splits source folders into train and val sets before processing clips.\n",
        "    Ensures that all clips from a source video stay in the same set.\n",
        "    \"\"\"\n",
        "    train_sources = {}\n",
        "    val_sources = {}\n",
        "\n",
        "    for category in os.listdir(dataset_path):  # Iterate over action categories\n",
        "        category_path = os.path.join(dataset_path, category)\n",
        "        if not os.path.isdir(category_path):\n",
        "            continue\n",
        "\n",
        "        instances = os.listdir(category_path)  # List all source folders (video IDs)\n",
        "        random.shuffle(instances)  # Shuffle instances before splitting\n",
        "\n",
        "        split_idx = int(len(instances) * train_ratio)\n",
        "        train_sources[category] = instances[:split_idx]  # First 80% for training\n",
        "        val_sources[category] = instances[split_idx:]  # Last 20% for validation\n",
        "\n",
        "    return train_sources, val_sources\n",
        "\n",
        "\n",
        "def process_dataset(dataset_path, sources_dict):\n",
        "    \"\"\"\n",
        "    Processes dataset based on a predefined list of sources.\n",
        "    \"\"\"\n",
        "    dataset = []\n",
        "    all_updated_metadata = []\n",
        "\n",
        "    for category, instances in tqdm(sources_dict.items()):\n",
        "        category_path = os.path.join(dataset_path, category)\n",
        "\n",
        "        for instance in instances:\n",
        "            instance_path = os.path.join(category_path, instance)\n",
        "            if not os.path.isdir(instance_path):\n",
        "                continue  # Skip non-directory files\n",
        "\n",
        "            # Load sampled frames\n",
        "            frames, frame_metadata = load_sampled_frames(instance_path)\n",
        "\n",
        "            # Create 8-frame clips\n",
        "            clips, updated_metadata, clip_indices = create_clips(frames, frame_metadata)\n",
        "\n",
        "\n",
        "            for i, clip in enumerate(clips):\n",
        "                dataset.append((clip, CATEGORY_INDEX[category]))  # Store (clip, label)\n",
        "\n",
        "                all_updated_metadata.append(updated_metadata[i])\n",
        "\n",
        "    return dataset, all_updated_metadata  # List of (clip, label)\n",
        "\n",
        "class VideoDataset(Dataset):\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        clip, label = self.dataset[idx]\n",
        "        return clip, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "from torch.utils.data import default_collate\n",
        "\n",
        "class VideoDataCollator:\n",
        "    \"\"\"\n",
        "    Custom data collator for TimeSFormer.\n",
        "    Converts (clip, label) tuples into a dictionary format.\n",
        "    \"\"\"\n",
        "    def __call__(self, features):\n",
        "        clips, labels = zip(*features)  # Unpack (clip, label)\n",
        "        batch = {\n",
        "            \"pixel_values\": torch.stack(clips),  # Stack clips into batch\n",
        "            \"labels\": torch.tensor(labels, dtype=torch.long)  # Convert labels to tensor\n",
        "        }\n",
        "        return batch\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "def count_classes(dataset):\n",
        "    \"\"\"\n",
        "    Function to print the number of clips of 8 created per class\n",
        "    \"\"\"\n",
        "    class_counts = Counter(label for _, label in dataset)\n",
        "    sorted_class_counts = dict(sorted(class_counts.items()))\n",
        "\n",
        "    for class_label, count in sorted_class_counts.items():\n",
        "        print(f\"Class {class_label}: {count} clips of 8\")\n",
        "\n",
        "    return sorted_class_counts\n",
        "\n",
        "#count_classes(train_dataset);\n",
        "\n",
        "# Split source folders into train & val\n",
        "train_sources, val_sources = split_sources(DATASET_PATH)\n",
        "\n",
        "# Process train and val sets separately\n",
        "train_dataset, train_metadata = process_dataset(DATASET_PATH, train_sources)\n",
        "val_dataset, val_metadata = process_dataset(DATASET_PATH, val_sources)\n",
        "\n",
        "dataset_size = len(train_dataset) + len(val_dataset)\n",
        "\n"
      ],
      "metadata": {
        "id": "U4V-1D0n_bEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in train_sources:  # Iterate through keys (category names)\n",
        "  print(f\"Category: {key}\")\n",
        "  for item in train_sources[key]:\n",
        "    print(item, end=', ')  # Iterate through\n",
        "  print()"
      ],
      "metadata": {
        "id": "ldx3kKHYf8Zh",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from transformers import TimesformerForVideoClassification, AutoImageProcessor\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n"
      ],
      "metadata": {
        "id": "0g_l7721jTiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xb5JOTyz_MO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_sources(dataset_path, train_ratio=0.8):\n",
        "    \"\"\"\n",
        "    Splits source folders into train and val sets before processing clips.\n",
        "    Ensures that all clips from a source video stay in the same set.\n",
        "    \"\"\"\n",
        "    train_sources = {}\n",
        "    val_sources = {}\n",
        "\n",
        "    for category in os.listdir(dataset_path):  # Iterate over action categories\n",
        "        category_path = os.path.join(dataset_path, category)\n",
        "        if not os.path.isdir(category_path):\n",
        "            continue\n",
        "\n",
        "        instances = os.listdir(category_path)  # List all source folders (video IDs)\n",
        "        random.shuffle(instances)  # Shuffle instances before splitting\n",
        "\n",
        "        split_idx = int(len(instances) * train_ratio)\n",
        "        train_sources[category] = instances[:split_idx]  # First 80% for training\n",
        "        val_sources[category] = instances[split_idx:]  # Last 20% for validation\n",
        "\n",
        "    return train_sources, val_sources"
      ],
      "metadata": {
        "id": "gbNnJybfpO4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GLOBAL MATRIX\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def global_matrix(dataset_dir = \"HMDB_simp\"):\n",
        "  CATEGORY_INDEX = {\n",
        "      \"brush_hair\": 0,\n",
        "      \"cartwheel\": 1,\n",
        "      \"catch\": 2,\n",
        "      \"chew\": 3,\n",
        "      \"climb\": 4,\n",
        "      \"climb_stairs\": 5,\n",
        "      \"draw_sword\": 6,\n",
        "      \"eat\": 7,\n",
        "      \"fencing\": 8,\n",
        "      \"flic_flac\": 9,\n",
        "      \"golf\": 10,\n",
        "      \"handstand\": 11,\n",
        "      \"kiss\": 12,\n",
        "      \"pick\": 13,\n",
        "      \"pour\": 14,\n",
        "      \"pullup\": 15,\n",
        "      \"pushup\": 16,\n",
        "      \"ride_bike\": 17,\n",
        "      \"shoot_bow\": 18,\n",
        "      \"shoot_gun\": 19,\n",
        "      \"situp\": 20,\n",
        "      \"smile\": 21,\n",
        "      \"smoke\": 22,\n",
        "      \"throw\": 23,\n",
        "      \"wave\": 24\n",
        "  }\n",
        "\n",
        "  MATR = []\n",
        "  for category_name in CATEGORY_INDEX:\n",
        "    category_path = os.path.join(dataset_dir, category_name)\n",
        "    if os.path.exists(category_path):\n",
        "      # subfolders inside the category\n",
        "      global_array = []\n",
        "      for folder in os.listdir(category_path):\n",
        "          folder_path = os.path.join(category_path, folder)\n",
        "\n",
        "          if os.path.isdir(folder_path):\n",
        "              files = os.listdir(folder_path)\n",
        "              number_of_jpgs = len(files)\n",
        "              global_array.append(number_of_jpgs)\n",
        "\n",
        "      MATR.append(global_array)\n",
        "\n",
        "  return MATR\n",
        "\n",
        "\n",
        "def print_matrix(matrix):\n",
        "    rows = len(matrix)\n",
        "    cols = len(matrix[0])\n",
        "\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            print(f'{matrix[i][j]:5}', end=' ')\n",
        "        print()\n",
        "\n",
        "\n",
        "MATR = global_matrix()\n",
        "Matr1 = np.array(MATR)"
      ],
      "metadata": {
        "id": "gEuWfetoNJWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "def plot_heatmap(MATR, category_names):\n",
        "    # Convert MATR to a numpy array if it's a list of lists\n",
        "    MATR_array = np.array(MATR)\n",
        "\n",
        "    # Create a heatmap without annotations (values in the cells)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    ax = sns.heatmap(MATR_array, annot=False, cmap='YlGnBu', cbar=True, linewidths=0.5, square=True, yticklabels=category_names)\n",
        "\n",
        "    # Set the title\n",
        "    ax.set_title(\"Heatmap of number of frames values\", fontsize=16)\n",
        "\n",
        "    # Set x and y labels based on categories or custom labels\n",
        "    ax.set_xlabel('Videos', fontsize=12)\n",
        "    ax.set_ylabel('Categories', fontsize=12)\n",
        "\n",
        "    # Display the plot\n",
        "    plt.show()\n",
        "\n",
        "category_names = [\n",
        "    \"brush_hair\", \"cartwheel\", \"catch\", \"chew\", \"climb\", \"climb_stairs\",\n",
        "    \"draw_sword\", \"eat\", \"fencing\", \"flic_flac\", \"golf\", \"handstand\",\n",
        "    \"kiss\", \"pick\", \"pour\", \"pullup\", \"pushup\", \"ride_bike\", \"shoot_bow\",\n",
        "    \"shoot_gun\", \"situp\", \"smile\", \"smoke\", \"throw\", \"wave\"\n",
        "]\n",
        "plot_heatmap(MATR, category_names)\n",
        "#print_matrix(MATR)"
      ],
      "metadata": {
        "id": "qx1BXtYboPTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example matrix MATR (25 categories x 50 videos)\n",
        "# Convert your actual data into a numpy array\n",
        "MATR = np.array(MATR)\n",
        "\n",
        "# Category names\n",
        "category_names = [\n",
        "    \"brush_hair\", \"cartwheel\", \"catch\", \"chew\", \"climb\", \"climb_stairs\",\n",
        "    \"draw_sword\", \"eat\", \"fencing\", \"flic_flac\", \"golf\", \"handstand\",\n",
        "    \"kiss\", \"pick\", \"pour\", \"pullup\", \"pushup\", \"ride_bike\", \"shoot_bow\",\n",
        "    \"shoot_gun\", \"situp\", \"smile\", \"smoke\", \"throw\", \"wave\"\n",
        "]\n",
        "\n",
        "# Calculating mean frames per category\n",
        "# The mean should be the sum of frames for each category divided by the number of videos\n",
        "mean_frames_category = np.sum(MATR, axis=1) / 50\n",
        "\n",
        "\n",
        "# Plotting the Mean Frames per Category\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(range(MATR.shape[0]), mean_frames_category, color='thistle')  # Lilac/purple color\n",
        "plt.title('Mean Frames per Category', fontsize=14)\n",
        "plt.xlabel('Category', fontsize=12)\n",
        "plt.ylabel('Mean Frames', fontsize=12)\n",
        "plt.xticks(range(MATR.shape[0]), category_names, rotation=90, fontsize=10)\n",
        "plt.grid(True, axis='y', linestyle='--', alpha=0.5, color='grey')  # Adding grey grid to the y-axis\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "diFjk97l9KL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "# Convert the list of lists into a numpy array\n",
        "MATR = np.array(MATR)\n",
        "\n",
        "# 1. Total number of frames per video (sum across rows for each column)\n",
        "total_frames_video = np.sum(MATR, axis=0)\n",
        "\n",
        "# 2. Total number of frames per category (sum across columns for each row)\n",
        "total_frames_category = np.sum(MATR, axis=1)\n",
        "\n",
        "# 3. Mean number of frames per video (mean across rows for each column)\n",
        "mean_frames_video = np.mean(MATR, axis=0)\n",
        "\n",
        "# 4. Mean number of frames per category (mean across columns for each row)\n",
        "mean_frames_category = np.mean(MATR, axis=1)\n",
        "\n",
        "# 5. Variance of frames per video (variance across rows for each column)\n",
        "var_frames_video = np.var(MATR, axis=0)\n",
        "\n",
        "# 6. Standard deviation of frames per video (std across rows for each column)\n",
        "std_frames_video = np.std(MATR, axis=0)\n",
        "\n",
        "# 7. Maximum and minimum number of frames per video\n",
        "max_frames_video = np.max(MATR, axis=0)\n",
        "min_frames_video = np.min(MATR, axis=0)\n",
        "\n",
        "# 8. Total number of frames across all videos and categories\n",
        "total_frames_all = np.sum(MATR)\n",
        "\n",
        "# 9. Skewness and Kurtosis (using scipy.stats)\n",
        "skew_frames_video = skew(MATR, axis=0)\n",
        "kurt_frames_video = kurtosis(MATR, axis=0)\n",
        "\n",
        "# 10. Percentiles (25th, 50th, 75th percentile per video)\n",
        "percentiles_video = np.percentile(MATR, [25, 50, 75], axis=0)\n",
        "\n",
        "# Print the results\n",
        "print(\"Total frames per video:\", total_frames_video)\n",
        "print(\"Total frames per category:\", total_frames_category)\n",
        "print(\"Mean frames per video:\", mean_frames_video)\n",
        "print(\"Mean frames per category:\", mean_frames_category)\n",
        "print(\"Variance frames per video:\", var_frames_video)\n",
        "print(\"Standard deviation frames per video:\", std_frames_video)\n",
        "print(\"Max frames per video:\", max_frames_video)\n",
        "print(\"Min frames per video:\", min_frames_video)\n",
        "print(\"Total frames across all videos and categories:\", total_frames_all)\n",
        "print(\"Skewness frames per video:\", skew_frames_video)\n",
        "print(\"Kurtosis frames per video:\", kurt_frames_video)\n",
        "print(\"Percentiles (25th, 50th, 75th) frames per video:\", percentiles_video)\n"
      ],
      "metadata": {
        "id": "BG0ehhnP8Gq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "# Example matrix MATR (25 categories x 50 videos)\n",
        "# Convert your actual data into a numpy array\n",
        "MATR = np.random.randint(1, 100, size=(25, 50))  # Example, replace with your actual data\n",
        "\n",
        "# Calculating statistics\n",
        "total_frames_video = np.sum(MATR, axis=0)\n",
        "total_frames_category = np.sum(MATR, axis=1)\n",
        "mean_frames_video = np.mean(MATR, axis=0)\n",
        "mean_frames_category = np.mean(MATR, axis=1)\n",
        "var_frames_video = np.var(MATR, axis=0)\n",
        "std_frames_video = np.std(MATR, axis=0)\n",
        "max_frames_video = np.max(MATR, axis=0)\n",
        "min_frames_video = np.min(MATR, axis=0)\n",
        "total_frames_all = np.sum(MATR)\n",
        "skew_frames_video = skew(MATR, axis=0)\n",
        "kurt_frames_video = kurtosis(MATR, axis=0)\n",
        "percentiles_video = np.percentile(MATR, [25, 50, 75], axis=0)\n",
        "\n",
        "# Plotting the statistics\n",
        "fig, axes = plt.subplots(4, 2, figsize=(15, 15))\n",
        "\n",
        "\n",
        "# Total frames per video\n",
        "axes[0, 0].bar(range(MATR.shape[1]), total_frames_video)\n",
        "axes[0, 0].set_title('Total Frames per Video')\n",
        "axes[0, 0].set_xlabel('Video Index')\n",
        "axes[0, 0].set_ylabel('Total Frames')\n",
        "\n",
        "\n",
        "# Total frames per category\n",
        "axes[0, 1].bar(range(MATR.shape[0]), total_frames_category)\n",
        "axes[0, 1].set_title('Total Frames per Category')\n",
        "axes[0, 1].set_xlabel('Category Index')\n",
        "axes[0, 1].set_ylabel('Total Frames')\n",
        "\n",
        "# Mean frames per video\n",
        "axes[1, 0].bar(range(MATR.shape[1]), mean_frames_video)\n",
        "axes[1, 0].set_title('Mean Frames per Video')\n",
        "axes[1, 0].set_xlabel('Video Index')\n",
        "axes[1, 0].set_ylabel('Mean Frames')\n",
        "\n",
        "\n",
        "# Mean frames per category\n",
        "axes[1, 1].bar(range(MATR.shape[0]), mean_frames_category)\n",
        "axes[1, 1].set_title('Mean Frames per Category')\n",
        "axes[1, 1].set_xlabel('Category Index')\n",
        "axes[1, 1].set_ylabel('Mean Frames')\n",
        "\n",
        "# Variance of frames per video\n",
        "axes[2, 0].bar(range(MATR.shape[1]), var_frames_video)\n",
        "axes[2, 0].set_title('Variance of Frames per Video')\n",
        "axes[2, 0].set_xlabel('Video Index')\n",
        "axes[2, 0].set_ylabel('Variance')\n",
        "\n",
        "# Standard deviation of frames per video\n",
        "axes[2, 1].bar(range(MATR.shape[1]), std_frames_video)\n",
        "axes[2, 1].set_title('Standard Deviation of Frames per Video')\n",
        "axes[2, 1].set_xlabel('Video Index')\n",
        "axes[2, 1].set_ylabel('Standard Deviation')\n",
        "\n",
        "# Maximum frames per video\n",
        "axes[3, 0].bar(range(MATR.shape[1]), max_frames_video)\n",
        "axes[3, 0].set_title('Max Frames per Video')\n",
        "axes[3, 0].set_xlabel('Video Index')\n",
        "axes[3, 0].set_ylabel('Max Frames')\n",
        "\n",
        "# Minimum frames per video\n",
        "axes[3, 1].bar(range(MATR.shape[1]), min_frames_video)\n",
        "axes[3, 1].set_title('Min Frames per Video')\n",
        "axes[3, 1].set_xlabel('Video Index')\n",
        "axes[3, 1].set_ylabel('Min Frames')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Skewness and Kurtosis plot (for each video)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(MATR.shape[1]), skew_frames_video, marker='o', color='b', label='Skewness')\n",
        "plt.title('Skewness of Frames per Video')\n",
        "plt.xlabel('Video Index')\n",
        "plt.ylabel('Skewness')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(MATR.shape[1]), kurt_frames_video, marker='o', color='r', label='Kurtosis')\n",
        "plt.title('Kurtosis of Frames per Video')\n",
        "plt.xlabel('Video Index')\n",
        "plt.ylabel('Kurtosis')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Percentiles plot (25th, 50th, 75th percentile)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(MATR.shape[1]), percentiles_video[0], label='25th Percentile', color='g')\n",
        "plt.plot(range(MATR.shape[1]), percentiles_video[1], label='50th Percentile (Median)', color='b')\n",
        "plt.plot(range(MATR.shape[1]), percentiles_video[2], label='75th Percentile', color='r')\n",
        "\n",
        "plt.title('Percentiles of Frames per Video')\n",
        "plt.xlabel('Video Index')\n",
        "plt.ylabel('Frames')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WfT3UC3L8Vya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Example means vector\n",
        "means = np.array([265.0, 74.32, 39.62, 99.02, 162.74, 78.92, 75.26, 89.0, 77.22,\n",
        "                  67.72, 80.48, 82.44, 180.02, 88.74, 171.02, 79.86, 93.22, 96.36,\n",
        "                  175.54, 94.16, 92.76, 71.24, 145.0, 99.02, 77.52])\n",
        "\n",
        "# Reshape means to a 2D array (25 rows, 1 column)\n",
        "means_reshaped = means.reshape(-1, 1)\n",
        "\n",
        "# Plot the heatmap without annotations (numbers inside cells)\n",
        "plt.figure(figsize=(10, 8))\n",
        "ax = sns.heatmap(means_reshaped, annot=False, cmap='YlGnBu', cbar=True,\n",
        "                 linewidths=0.5, square=True, xticklabels=False, yticklabels=category_names)\n",
        "\n",
        "# Set the title\n",
        "ax.set_title(\"Heatmap of Means\", fontsize=16)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RcobV3m6sB92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Example means vector\n",
        "means = np.array([265.0, 74.32, 39.62, 99.02, 162.74, 78.92, 75.26, 89.0, 77.22,\n",
        "                  67.72, 80.48, 82.44, 180.02, 88.74, 171.02, 79.86, 93.22, 96.36,\n",
        "                  175.54, 94.16, 92.76, 71.24, 145.0, 99.02, 77.52])\n",
        "\n",
        "# Reshape means to a 2D array (1 row, 25 columns)\n",
        "means_reshaped = means.reshape(1, -1)\n",
        "\n",
        "# Plot the heatmap as a row\n",
        "plt.figure(figsize=(12, 2))  # Adjust the figure size to make the row more visible\n",
        "ax = sns.heatmap(means_reshaped, annot=False, cmap='YlGnBu', cbar=True,\n",
        "                 linewidths=0.5, square=False, xticklabels=True, yticklabels=False)\n",
        "\n",
        "# Set the title\n",
        "ax.set_title(\"Heatmap of Row Means\", fontsize=16)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8vNhHztks4sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assume global_matrix is a NumPy array of shape (25, 50)\n",
        "def category_stats(global_matrix):\n",
        "    for idx, row in enumerate(global_matrix):\n",
        "        mean_val = np.mean(row)\n",
        "        median_val = np.median(row)\n",
        "        std_val = np.std(row)\n",
        "        min_val = np.min(row)\n",
        "        max_val = np.max(row)\n",
        "        print(f'Category {idx+1}: Mean={mean_val:.2f}, Median={median_val}, Std={std_val:.2f}, Min={min_val}, Max={max_val}')\n"
      ],
      "metadata": {
        "id": "qXJ1axrQmLwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "dataset_dir = \"HMDB_simp\"\n",
        "\n",
        "mean_number_per_categ = []\n",
        "names = []\n",
        "arr = []\n",
        "global_matrix = []\n",
        "for category_name in CATEGORY_INDEX:\n",
        "  category_path = os.path.join(dataset_dir, category_name)\n",
        "\n",
        "\n",
        "  frames_number_per_video = []\n",
        "  if os.path.exists(category_path):\n",
        "    # subfolders inside the category\n",
        "    global_array = []\n",
        "    for folder in os.listdir(category_path):\n",
        "        folder_path = os.path.join(category_path, folder)\n",
        "\n",
        "        if os.path.isdir(folder_path):\n",
        "            files = os.listdir(folder_path)\n",
        "            number_of_jpgs = len(files)\n",
        "            global_array.append(number_of_jpgs)\n",
        "            frames_number_per_video.append(number_of_jpgs)\n",
        "\n",
        "    mean_jpgs_among_videos = np.mean(frames_number_per_video)\n",
        "    mean_number_per_categ.append(mean_jpgs_among_videos)\n",
        "    names.append([category_name])\n",
        "    arr.append([category_name, mean_jpgs_among_videos])\n",
        "    global_matrix.append(global_array)\n",
        "    #print(f\"'{category_name}': {mean_jpgs_among_videos}\" )\n",
        "\n",
        "\n",
        "mean_number_per_categ.sort()"
      ],
      "metadata": {
        "id": "2vUdGUNffaVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_data = sorted(arr, key=lambda x: x[1])\n",
        "\n",
        "print(\"Average number of frames per category\")\n",
        "print(\"----------------------------------\")\n",
        "for el in sorted_data:\n",
        "  print(f\"{el[0]:>15}: {el[1]:>7}\" )"
      ],
      "metadata": {
        "id": "XwYxE-g8cSU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (mean_number, category_name)\n",
        "# reverse CATEGORY_INDEX to map index -> category\n",
        "index_to_category = {index: name for name, index in CATEGORY_INDEX.items()}\n",
        "\n",
        "#  paired list\n",
        "paired = [(mean_number_per_categ[i], index_to_category[i]) for i in range(len(mean_number_per_categ))]\n",
        "paired_sorted = sorted(paired)\n",
        "\n",
        "sorted_means, sorted_names = zip(*paired_sorted)\n",
        "sorted_means = list(sorted_means)\n",
        "sorted_names = list(sorted_names)\n",
        "\n",
        "# Print the result\n",
        "for name, mean in zip(sorted_names, sorted_means):\n",
        "    print(f\"{name:>15}: {mean:>7}\")\n"
      ],
      "metadata": {
        "id": "Ou_viSNZQz6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reverse mapping: index to category name\n",
        "index_to_category = {index: name for name, index in CATEGORY_INDEX.items()}\n",
        "combined = [(index_to_category[i], mean_number_per_categ[i]) for i in range(len(mean_number_per_categ))]\n",
        "sorted_combined = sorted(combined, key=lambda x: x[1])\n",
        "\n",
        "\n",
        "print(\"Average number of frames per class\")\n",
        "print(\"----------------------------------\")\n",
        "for category, frames in sorted_combined:\n",
        "\n",
        "    print(f\"{category:>15} {frames:>7}\")\n"
      ],
      "metadata": {
        "id": "BCUjzROFO7iE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vzj5DO1p5Zk3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}