{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FUrn8O3DACP4"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "ezWcNB66APln",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!unzip /content/drive/MyDrive/HMDB_simp.zip -d /content/HMDB_simp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YBWzeuZZOz6R"
   },
   "outputs": [],
   "source": [
    "!pip install transformers torch torchvision datasets evaluate torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NjqkzwpFZ2t"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okOhTovRFbzP"
   },
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "i2jJmcaGAuv1"
   },
   "outputs": [],
   "source": [
    "CATEGORY_INDEX = {\n",
    "    \"brush_hair\": 0,\n",
    "    \"cartwheel\": 1,\n",
    "    \"catch\": 2,\n",
    "    \"chew\": 3,\n",
    "    \"climb\": 4,\n",
    "    \"climb_stairs\": 5,\n",
    "    \"draw_sword\": 6,\n",
    "    \"eat\": 7,\n",
    "    \"fencing\": 8,\n",
    "    \"flic_flac\": 9,\n",
    "    \"golf\": 10,\n",
    "    \"handstand\": 11,\n",
    "    \"kiss\": 12,\n",
    "    \"pick\": 13,\n",
    "    \"pour\": 14,\n",
    "    \"pullup\": 15,\n",
    "    \"pushup\": 16,\n",
    "    \"ride_bike\": 17,\n",
    "    \"shoot_bow\": 18,\n",
    "    \"shoot_gun\": 19,\n",
    "    \"situp\": 20,\n",
    "    \"smile\": 21,\n",
    "    \"smoke\": 22,\n",
    "    \"throw\": 23,\n",
    "    \"wave\": 24\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "P--_dzefBom3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "# Transformation: Resize to 224x224 and Convert to Tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "def load_sampled_frames(frame_dir, frame_rate=8):\n",
    "    \"\"\"\n",
    "    Load every [frame_rate]-th frame from a directory and apply transformations.\n",
    "    \"\"\"\n",
    "    frame_files = sorted(os.listdir(frame_dir))  # Ensure frames are in order\n",
    "    sampled_frames = []\n",
    "    frame_metadata = []\n",
    "\n",
    "    for i in range(0, len(frame_files), frame_rate):\n",
    "        frame_path = os.path.join(frame_dir, frame_files[i])\n",
    "        frame = Image.open(frame_path).convert(\"RGB\")  # Convert to RGB\n",
    "        frame = transform(frame)  # Apply transformations\n",
    "        sampled_frames.append(frame)\n",
    "        frame_metadata.append({'index': i, 'used_in_clip': False, 'file_path': frame_path}) #set up\n",
    "\n",
    "    return sampled_frames, frame_metadata  # List of torch tensors\n",
    "\n",
    "def create_clips(frames, frame_metadata, clip_size=8):\n",
    "    \"\"\"\n",
    "    Given a list of sampled frames, create multiple [clip_size]-frame clips.\n",
    "    \"\"\"\n",
    "    clips = []\n",
    "    clip_indices = []\n",
    "    updated_metadata = []\n",
    "    if len(frames) < clip_size:\n",
    "        return clips, updated_metadata, clip_indices  # Not enough frames to create a clip\n",
    "    for i in range(0, len(frames) - clip_size + 1, clip_size):  # Sliding window\n",
    "        clip = torch.stack(frames[i:i + clip_size])  # Stack into (clip_size, 3, 224, 224)\n",
    "        clips.append(clip)\n",
    "        clip_indices.append([frame_metadata[j]['index'] for j in range(i, i + clip_size)])\n",
    "        clip_metadata = [frame_metadata[j]['file_path'] for j in range(i, i + clip_size)]\n",
    "        updated_metadata.append(clip_metadata)\n",
    "\n",
    "    return clips, updated_metadata, clip_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EZ5uc9RyCaP8"
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = \"/content/HMDB_simp/HMDB_simp\"\n",
    "\n",
    "import random\n",
    "\n",
    "def split_sources(dataset_path, train_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Splits source folders into train and val sets before processing clips.\n",
    "    Ensures that all clips from a source video stay in the same set.\n",
    "    \"\"\"\n",
    "    train_sources = {}\n",
    "    val_sources = {}\n",
    "\n",
    "    for category in os.listdir(dataset_path):  # Iterate over action categories\n",
    "        category_path = os.path.join(dataset_path, category)\n",
    "        if not os.path.isdir(category_path):\n",
    "            continue\n",
    "\n",
    "        instances = os.listdir(category_path)  # List all source folders (video IDs)\n",
    "        random.shuffle(instances)  # Shuffle instances before splitting\n",
    "\n",
    "        split_idx = int(len(instances) * train_ratio)\n",
    "        train_sources[category] = instances[:split_idx]  # First 80% for training\n",
    "        val_sources[category] = instances[split_idx:]  # Last 20% for validation\n",
    "\n",
    "    return train_sources, val_sources\n",
    "\n",
    "\n",
    "def process_dataset(dataset_path, sources_dict):\n",
    "    \"\"\"\n",
    "    Processes dataset based on a predefined list of sources.\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "    all_updated_metadata = []\n",
    "\n",
    "    for category, instances in tqdm(sources_dict.items()):\n",
    "        category_path = os.path.join(dataset_path, category)\n",
    "\n",
    "        for instance in instances:\n",
    "            instance_path = os.path.join(category_path, instance)\n",
    "            if not os.path.isdir(instance_path):\n",
    "                continue  # Skip non-directory files\n",
    "\n",
    "            # Load sampled frames\n",
    "            frames, frame_metadata = load_sampled_frames(instance_path)\n",
    "\n",
    "            # Create 8-frame clips\n",
    "            clips, updated_metadata, clip_indices = create_clips(frames, frame_metadata)\n",
    "\n",
    "            for i, clip in enumerate(clips):\n",
    "                dataset.append((clip, CATEGORY_INDEX[category]))  # Store (clip, label)\n",
    "                all_updated_metadata.append(updated_metadata[i])\n",
    "\n",
    "    return dataset, all_updated_metadata  # List of (clip, label)\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        clip, label = self.dataset[idx]\n",
    "        return clip, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "from torch.utils.data import default_collate\n",
    "\n",
    "class VideoDataCollator:\n",
    "    \"\"\"\n",
    "    Custom data collator for TimeSFormer.\n",
    "    Converts (clip, label) tuples into a dictionary format.\n",
    "    \"\"\"\n",
    "    def __call__(self, features):\n",
    "        clips, labels = zip(*features)  # Unpack (clip, label)\n",
    "        batch = {\n",
    "            \"pixel_values\": torch.stack(clips),  # Stack clips into batch\n",
    "            \"labels\": torch.tensor(labels, dtype=torch.long)  # Convert labels to tensor\n",
    "        }\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def count_classes(dataset):\n",
    "    \"\"\"\n",
    "    Function to print the number of clips of 8 created per class\n",
    "    \"\"\"\n",
    "    class_counts = Counter(label for _, label in dataset)\n",
    "    sorted_class_counts = dict(sorted(class_counts.items()))\n",
    "\n",
    "    for class_label, count in sorted_class_counts.items():\n",
    "        print(f\"Class {class_label}: {count} clips of 8\")\n",
    "\n",
    "    return sorted_class_counts\n",
    "\n",
    "#count_classes(train_dataset);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98,
     "referenced_widgets": [
      "0e9e96db80ac45c4ad584ac25d83f9e8",
      "8fcdf06bfd764986b8764eec821550de",
      "2127ace456424256b1c5f6a9cd3772bc",
      "3d02c673582043fdae208291f144d3de",
      "d3d07bd730a2461fb798123e3d3688da",
      "2ffc369a5fb54bc8b6e29fa3b0b37a1d",
      "36781039adf84eca988b39f2cccc5734",
      "8c7ab1ea27b647e8906a55436284b5bc",
      "44da2684ddb64a579e5ec910b6074120",
      "46101c45c4d34df1a23157b51df1ffba",
      "dd82fc869e2d4bac96452a60f6119644",
      "5e23bfdf471f46a08f3980ed7b21b7ed",
      "4254d17705e645858f4dcfbdb9677b42",
      "f970caefed26434d9d988e3216197138",
      "19a8db15f3ed4a1190c692ea0ad5f2e3",
      "e8c8dfe4eac949ab9df7c1caf3879097",
      "c21c84321da740e7b726d04dfaf1c5d7",
      "0bad71e6ab3a4b5d8533a1c54ad9a246",
      "055fb61a8e1d4fdda2afde61b560113e",
      "0b9b05455e824c9eac8dc77503f5de3f",
      "2578b3a67ec64acba98015ad9d9d73bd",
      "d384e59905964edaac18d4beb6deaa32"
     ]
    },
    "collapsed": true,
    "id": "dWD2A1WTCTO7",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "9b9963a8-3e9e-4ff2-8d3f-93e1b07671af"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e9e96db80ac45c4ad584ac25d83f9e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e23bfdf471f46a08f3980ed7b21b7ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clips: 1627, Train: 1318, Val: 309\n"
     ]
    }
   ],
   "source": [
    "# Split source folders into train & val\n",
    "train_sources, val_sources = split_sources(DATASET_PATH)\n",
    "\n",
    "# Process train and val sets separately\n",
    "train_dataset, train_metadata = process_dataset(DATASET_PATH, train_sources)\n",
    "val_dataset, val_metadata = process_dataset(DATASET_PATH, val_sources)\n",
    "\n",
    "dataset_size = len(train_dataset) + len(val_dataset)\n",
    "\n",
    "print(f\"Total clips: {dataset_size}, Train: {len(train_dataset)}, Val: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E38OobPnIIb6"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2Jrj0STIKLa"
   },
   "source": [
    "## TimeSFormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "FSbE-vwYICqB",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "565ed3d1-663c-41cd-98cf-b0a55c35c2fc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/models/videomae/feature_extraction_videomae.py:28: FutureWarning: The class VideoMAEFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use VideoMAEImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Some weights of TimesformerForVideoClassification were not initialized from the model checkpoint at facebook/timesformer-base-finetuned-k400 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([400, 768]) in the checkpoint and torch.Size([25, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([400]) in the checkpoint and torch.Size([25]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model on: cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoFeatureExtractor, AutoModelForVideoClassification\n",
    "\n",
    "\n",
    "extractor = AutoFeatureExtractor.from_pretrained(\"facebook/timesformer-base-finetuned-k400\")\n",
    "model = AutoModelForVideoClassification.from_pretrained(\n",
    "    \"facebook/timesformer-base-finetuned-k400\",\n",
    "    num_labels=len(CATEGORY_INDEX),  # Adjust for our dataset\n",
    "    ignore_mismatched_sizes=True,\n",
    ")\n",
    "\n",
    "# Send model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(f\"Model on: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "FZCcJnr2JL5X"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchmetrics\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import AutoFeatureExtractor, AutoModelForVideoClassification, TrainingArguments, Trainer\n",
    "\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "top5_metric = torchmetrics.classification.Accuracy(top_k=5, task=\"multiclass\", num_classes=len(CATEGORY_INDEX)).to(device)\n",
    "\n",
    "# Compute Metrics Function\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = torch.tensor(logits).argmax(dim=1)\n",
    "\n",
    "    # Compute Accuracy\n",
    "    top1_acc = accuracy_metric.compute(predictions=predictions.numpy(), references=labels)[\"accuracy\"]\n",
    "\n",
    "    # Compute Top-5 Accuracy\n",
    "    top5_acc = top5_metric(torch.tensor(logits).to(device), torch.tensor(labels).to(device)).item()\n",
    "\n",
    "    # Compute F1-score (macro)\n",
    "    f1 = f1_metric.compute(predictions=predictions.numpy(), references=labels, average=\"macro\")[\"f1\"]\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": top1_acc,\n",
    "        \"top-5 accuracy\": top5_acc,\n",
    "        \"f1-score\": f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 512
    },
    "id": "ARn0w9fRK1q3",
    "outputId": "f27f8ae2-67d7-4dc6-c844-79e84d5a7c0a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "<ipython-input-11-14e7e5a34a30>:20: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkarkartem\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250310_141201-cib7l000</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/karkartem/huggingface/runs/cib7l000' target=\"_blank\">./timesformer_output</a></strong> to <a href='https://wandb.ai/karkartem/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/karkartem/huggingface' target=\"_blank\">https://wandb.ai/karkartem/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/karkartem/huggingface/runs/cib7l000' target=\"_blank\">https://wandb.ai/karkartem/huggingface/runs/cib7l000</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1650' max='1650' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1650/1650 1:04:37, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Top-5 accuracy</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.508000</td>\n",
       "      <td>0.645068</td>\n",
       "      <td>0.825243</td>\n",
       "      <td>0.970874</td>\n",
       "      <td>0.790915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.076700</td>\n",
       "      <td>0.595146</td>\n",
       "      <td>0.844660</td>\n",
       "      <td>0.977346</td>\n",
       "      <td>0.828910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.537473</td>\n",
       "      <td>0.857605</td>\n",
       "      <td>0.980583</td>\n",
       "      <td>0.852075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.499854</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.977346</td>\n",
       "      <td>0.857364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.493607</td>\n",
       "      <td>0.877023</td>\n",
       "      <td>0.977346</td>\n",
       "      <td>0.858724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1650, training_loss=0.23152913113689105, metrics={'train_runtime': 3881.9868, 'train_samples_per_second': 1.698, 'train_steps_per_second': 0.425, 'total_flos': 5.77465293172949e+18, 'train_loss': 0.23152913113689105, 'epoch': 5.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./timesformer_output\",  # Save checkpoints\n",
    "    evaluation_strategy=\"epoch\",  # Evaluate after every epoch\n",
    "    save_strategy=\"epoch\",  # Save model after each epoch\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",  # TensorBoard logs\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,  # Keep only last 2 checkpoints\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    push_to_hub=False\n",
    ")\n",
    "\n",
    "data_collator = VideoDataCollator()\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=extractor,  # Feature extractor\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "# Train Model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oau7CjykRFFN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "055fb61a8e1d4fdda2afde61b560113e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b9b05455e824c9eac8dc77503f5de3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0bad71e6ab3a4b5d8533a1c54ad9a246": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0e9e96db80ac45c4ad584ac25d83f9e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8fcdf06bfd764986b8764eec821550de",
       "IPY_MODEL_2127ace456424256b1c5f6a9cd3772bc",
       "IPY_MODEL_3d02c673582043fdae208291f144d3de"
      ],
      "layout": "IPY_MODEL_d3d07bd730a2461fb798123e3d3688da"
     }
    },
    "19a8db15f3ed4a1190c692ea0ad5f2e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2578b3a67ec64acba98015ad9d9d73bd",
      "placeholder": "​",
      "style": "IPY_MODEL_d384e59905964edaac18d4beb6deaa32",
      "value": " 25/25 [00:11&lt;00:00,  2.48it/s]"
     }
    },
    "2127ace456424256b1c5f6a9cd3772bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c7ab1ea27b647e8906a55436284b5bc",
      "max": 25,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_44da2684ddb64a579e5ec910b6074120",
      "value": 25
     }
    },
    "2578b3a67ec64acba98015ad9d9d73bd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ffc369a5fb54bc8b6e29fa3b0b37a1d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36781039adf84eca988b39f2cccc5734": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3d02c673582043fdae208291f144d3de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_46101c45c4d34df1a23157b51df1ffba",
      "placeholder": "​",
      "style": "IPY_MODEL_dd82fc869e2d4bac96452a60f6119644",
      "value": " 25/25 [00:53&lt;00:00,  1.78s/it]"
     }
    },
    "4254d17705e645858f4dcfbdb9677b42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c21c84321da740e7b726d04dfaf1c5d7",
      "placeholder": "​",
      "style": "IPY_MODEL_0bad71e6ab3a4b5d8533a1c54ad9a246",
      "value": "100%"
     }
    },
    "44da2684ddb64a579e5ec910b6074120": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "46101c45c4d34df1a23157b51df1ffba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e23bfdf471f46a08f3980ed7b21b7ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4254d17705e645858f4dcfbdb9677b42",
       "IPY_MODEL_f970caefed26434d9d988e3216197138",
       "IPY_MODEL_19a8db15f3ed4a1190c692ea0ad5f2e3"
      ],
      "layout": "IPY_MODEL_e8c8dfe4eac949ab9df7c1caf3879097"
     }
    },
    "8c7ab1ea27b647e8906a55436284b5bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8fcdf06bfd764986b8764eec821550de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ffc369a5fb54bc8b6e29fa3b0b37a1d",
      "placeholder": "​",
      "style": "IPY_MODEL_36781039adf84eca988b39f2cccc5734",
      "value": "100%"
     }
    },
    "c21c84321da740e7b726d04dfaf1c5d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d384e59905964edaac18d4beb6deaa32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d3d07bd730a2461fb798123e3d3688da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd82fc869e2d4bac96452a60f6119644": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e8c8dfe4eac949ab9df7c1caf3879097": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f970caefed26434d9d988e3216197138": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_055fb61a8e1d4fdda2afde61b560113e",
      "max": 25,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0b9b05455e824c9eac8dc77503f5de3f",
      "value": 25
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
